{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa9aaea7",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f704748",
   "metadata": {},
   "source": [
    "###  What is Regression ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ea7235",
   "metadata": {},
   "source": [
    "Regression, in simple words,is method of estimating a value based on another value. \n",
    "For example estimating height based on age.\n",
    "- This method is used for,\n",
    "    1. forcasting\n",
    "    2. Finding out cause and effect relationship between values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbcbbaa",
   "metadata": {},
   "source": [
    "### What is Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b46d24e",
   "metadata": {},
   "source": [
    "Linear Regression is supervised Machine learning algorithm.\n",
    "\n",
    "Linear regression is a type of regression analysis where there is a linear relationship between the independent(x) and dependent(y) variable. There can be positive Linear Relationship or Negative Linear Relationship\n",
    "\n",
    "**Objective of Linear Regression** :\n",
    "To fit a **best fit line** in such a manner that the differences between the distance of the actual data points from the plotted curve/line is minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36140232",
   "metadata": {},
   "source": [
    "\n",
    "### Types of Linear Regression\n",
    "- 1 Simple Linear Regression\n",
    "- 2 Miltiple Linear Regression\n",
    "- 3 Polynomial Linear Regression \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b39d34c",
   "metadata": {},
   "source": [
    "### Simple Linear Regreesion\n",
    "\n",
    "   It is an approach for predicting Y (dependent Variable) on the basis of single independent variable   \n",
    "   It assumes that there is approximately a linear relationship between X and Y\n",
    "\n",
    "   this is geiven by    **Y ≈ β1X + β0** \n",
    "   where \n",
    "   - X is independent variable\n",
    "   - Y is the dependent variable\n",
    "   - β1 is the slop (or coefficient or weight)\n",
    "   - β0 is y **intercept** when x = 0, (or offset)\n",
    "\n",
    "β0,β1, are two unknow constants that represents intercent and slop terms in the linear model.\n",
    "These **β0,β1** are know as model **coefficents** or **model parameters**\n",
    "\n",
    "Once we train the model with our training data to procduce estimates  β0 and β1 we can predict the future values on the basis of particular x value by computing\n",
    "\n",
    "  **yhat = β0hat + β1hat * x**   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bcdd00",
   "metadata": {},
   "source": [
    "### Mathametical Intution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee84156",
   "metadata": {},
   "source": [
    "#### How to find the values of Coefficients (β0 and β1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b3744c",
   "metadata": {},
   "source": [
    "The coefficients can be find in two different ways\n",
    " - **Closed form** \n",
    "     - Uses direct formula - __[wikipedia](https://en.wikipedia.org/wiki/Closed-form_expression)__           \n",
    "     - also called as Ordinary least square ( LinearRegression() in scikit learn uses OLS method by default)\n",
    " - **Non Closed form** - uses differenciation \n",
    "     - Solved by Gradient decent (SGDRegressor() in scikit learn used gradient decent)\n",
    "     \n",
    "\n",
    "__Why are we using Gradient Decent instead of direct formula from OLS?__\n",
    " - When the dimentionlity increases the complexity of calculation incrases with OLS formula. OLS is considered when the dataset is very small.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1c354d",
   "metadata": {},
   "source": [
    "### Ordinary Least Squre Method (Closed Form)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c89657",
   "metadata": {},
   "source": [
    "OLS method tries to find the β0 and β1 which minimizes the sum of squared errors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9df1fc45",
   "metadata": {},
   "source": [
    "<img src=\"img/OLs_closedForm.jpeg\" width =\"500\" height=500 >"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "253340fb",
   "metadata": {},
   "source": [
    "###### Lets build this equation from scarch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664f2603",
   "metadata": {},
   "source": [
    "Assuming that independent and dependent variable are linear in nature, we try to fit \"best line of fit\" that tries to pass through all the data poins as close as possible to reduce the error (also called as residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95d632f",
   "metadata": {},
   "source": [
    "<img src=\"img/decompose.jpeg\" width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db8ae7",
   "metadata": {},
   "source": [
    "Here d1,d2,d3,d4....dn represents errors(residuals)\n",
    "then, Error can be written has\n",
    "\n",
    "\n",
    "$$d_{1} + d_{2} + d_{3} + d_{4} + ....+ d_{n}$$\n",
    "\n",
    "Errors can be negative or positive values, this makes errors to cancel out at somepoint. To overcome this issue and find the total errors, we square them, now the equation will be,\n",
    "\n",
    "$$ d_{1}^2 + d_{2}^2 + d_{3}^2 + d_{4}^2 + ....+ d_{n}^2$$\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d99738",
   "metadata": {},
   "source": [
    "###### Why modulus is not used to convert the errors to posivite values?\n",
    "\n",
    "There are two reasons,\n",
    "1. we want to penalize outliers\n",
    "2. Mod can not be differentiable at origin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bb6e9a",
   "metadata": {},
   "source": [
    "now the Error term can be written as,\n",
    "<img src=\"img/Error_term.jpeg\" width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e4db8a",
   "metadata": {},
   "source": [
    "This E is now referred as **Error Function** or **Cost Function**\n",
    "\n",
    "(You will see Error term is also represented by **J** in some books)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdd41a4",
   "metadata": {},
   "source": [
    "Decomposing the error term further more,\n",
    "<img src=\"img/errorfunction.jpeg\" width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfb7411",
   "metadata": {},
   "source": [
    "Now we have Error function decomposed, we have to now find the values of **β0** and **β1** which minimizes the error.\n",
    "\n",
    "\n",
    "\n",
    "From theory we know , y = f(x), meaning, y is function of x, that is change in x will change the values of y.\n",
    "\n",
    "Similarly, change in **β0** and **β1** will change the values of error and finds the minimum errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e89cadf",
   "metadata": {},
   "source": [
    "From maths, we know, \n",
    "<img src=\"img/DerivativesBasics.jpeg\" width='500'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eb9e7a",
   "metadata": {},
   "source": [
    "To find the minimum value of error function, we have to carry out two steps,\n",
    "1. Find the partial derivatives of errors with respect to β0 and β1\n",
    "2. set up the derivatives to 0 and find the critical points, where the slop of the tangent line becomes 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318bf6a8",
   "metadata": {},
   "source": [
    "Finding β0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d57cc8",
   "metadata": {},
   "source": [
    "<img src=\"img/Beta0.jpeg\" width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe17573",
   "metadata": {},
   "source": [
    "Finding  β1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd91605b",
   "metadata": {},
   "source": [
    "<img src=\"img/beta1.jpeg\" width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6a5dd0",
   "metadata": {},
   "source": [
    "Find the example here - __[Github](https://git.io/JK6sS)__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
